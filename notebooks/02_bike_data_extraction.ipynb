{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80bc630-9fc2-4178-992c-50968aebf8a1",
   "metadata": {},
   "source": [
    "# Bike Count Data Extraction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdb001-1816-4b0d-9af6-c8f2e14f6f86",
   "metadata": {},
   "source": [
    "The raw bike count data was downloaded from Open Data Paris [(comptage vélo)](https://opendata.paris.fr/explore/dataset/comptage-velo-historique-donnees-compteurs/information) and covers the period from 2019 to 2024.\n",
    "\n",
    "The dataset includes measurements from dozens of bike counting sites across Paris. For the current analysis, I selected five sites that serve as reasonable proxies for recreational cycling routes that I personally use.\n",
    "\n",
    "This notebook focuses on the steps required to extract, filter, and concatenate data from these five sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c19165-a817-4123-8981-693c69a0c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# define directory variables\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "DATA_DIR = REPO_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20833b0-510d-4f78-8abe-9ffc7d5332e9",
   "metadata": {},
   "source": [
    "### Data Quality & Structural Notes\n",
    "\n",
    "- Date/time formatting was inconsistent across years and was normalized to a single format during preprocessing.\n",
    "\n",
    "- The pyarrow engine had difficulty parsing the 2024 data file, requiring additional steps to ensure correct site_id values.\n",
    "\n",
    "- The number of counters per site varies over time (ranging from 1 to 4), which has implications for aggregation and longitudinal comparisons.\n",
    "\n",
    "- Each site records traffic in both road directions.\n",
    "\n",
    "- At the Pont du Garigliano site, two distinct site_id values correspond to traffic flowing in opposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2bbe61-06c5-4e80-91c0-6f12baacdafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                                   object\n",
      "date_time_dt     datetime64[ns, Europe/Paris]\n",
      "site_id                        string[python]\n",
      "site_name_raw                  string[python]\n",
      "site_name                      string[python]\n",
      "counter_id                     string[python]\n",
      "counter_name                   string[python]\n",
      "count                                   Int64\n",
      "coords                                 object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date_time_dt</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name_raw</th>\n",
       "      <th>site_name</th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>count</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01 07:00:00+01:00</td>\n",
       "      <td>100047535</td>\n",
       "      <td>Pont du Garigliano NO-SE</td>\n",
       "      <td>pont du garigliano</td>\n",
       "      <td>100047535-SC</td>\n",
       "      <td>pont du garigliano no-se</td>\n",
       "      <td>3</td>\n",
       "      <td>48.839927,2.267151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-04 02:00:00+01:00</td>\n",
       "      <td>100047535</td>\n",
       "      <td>Pont du Garigliano NO-SE</td>\n",
       "      <td>pont du garigliano</td>\n",
       "      <td>100047535-SC</td>\n",
       "      <td>pont du garigliano no-se</td>\n",
       "      <td>1</td>\n",
       "      <td>48.839927,2.267151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-07 06:00:00+01:00</td>\n",
       "      <td>100047535</td>\n",
       "      <td>Pont du Garigliano NO-SE</td>\n",
       "      <td>pont du garigliano</td>\n",
       "      <td>100047535-SC</td>\n",
       "      <td>pont du garigliano no-se</td>\n",
       "      <td>13</td>\n",
       "      <td>48.839927,2.267151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-07 07:00:00+01:00</td>\n",
       "      <td>100047535</td>\n",
       "      <td>Pont du Garigliano NO-SE</td>\n",
       "      <td>pont du garigliano</td>\n",
       "      <td>100047535-SC</td>\n",
       "      <td>pont du garigliano no-se</td>\n",
       "      <td>55</td>\n",
       "      <td>48.839927,2.267151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-07 08:00:00+01:00</td>\n",
       "      <td>100047535</td>\n",
       "      <td>Pont du Garigliano NO-SE</td>\n",
       "      <td>pont du garigliano</td>\n",
       "      <td>100047535-SC</td>\n",
       "      <td>pont du garigliano no-se</td>\n",
       "      <td>114</td>\n",
       "      <td>48.839927,2.267151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521217</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-20 10:00:00+01:00</td>\n",
       "      <td>100047546</td>\n",
       "      <td>Face au 70 quai de Bercy</td>\n",
       "      <td>quai de bercy</td>\n",
       "      <td>100047546-103047546</td>\n",
       "      <td>face au 70 quai de bercy s-n</td>\n",
       "      <td>70</td>\n",
       "      <td>48.8295233, 2.38699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521218</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-24 04:00:00+01:00</td>\n",
       "      <td>100047546</td>\n",
       "      <td>Face au 70 quai de Bercy</td>\n",
       "      <td>quai de bercy</td>\n",
       "      <td>100047546-103047546</td>\n",
       "      <td>face au 70 quai de bercy s-n</td>\n",
       "      <td>0</td>\n",
       "      <td>48.8295233, 2.38699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521219</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-25 02:00:00+01:00</td>\n",
       "      <td>100047546</td>\n",
       "      <td>Face au 70 quai de Bercy</td>\n",
       "      <td>quai de bercy</td>\n",
       "      <td>100047546-103047546</td>\n",
       "      <td>face au 70 quai de bercy s-n</td>\n",
       "      <td>0</td>\n",
       "      <td>48.8295233, 2.38699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521220</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-29 05:00:00+01:00</td>\n",
       "      <td>100047546</td>\n",
       "      <td>Face au 70 quai de Bercy</td>\n",
       "      <td>quai de bercy</td>\n",
       "      <td>100047546-103047546</td>\n",
       "      <td>face au 70 quai de bercy s-n</td>\n",
       "      <td>4</td>\n",
       "      <td>48.8295233, 2.38699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521221</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12-31 09:00:00+01:00</td>\n",
       "      <td>100047546</td>\n",
       "      <td>Face au 70 quai de Bercy</td>\n",
       "      <td>quai de bercy</td>\n",
       "      <td>100047546-103047546</td>\n",
       "      <td>face au 70 quai de bercy s-n</td>\n",
       "      <td>56</td>\n",
       "      <td>48.8295233, 2.38699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737758 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year              date_time_dt    site_id             site_name_raw  \\\n",
       "452      2019 2019-01-01 07:00:00+01:00  100047535  Pont du Garigliano NO-SE   \n",
       "453      2019 2019-01-04 02:00:00+01:00  100047535  Pont du Garigliano NO-SE   \n",
       "454      2019 2019-01-07 06:00:00+01:00  100047535  Pont du Garigliano NO-SE   \n",
       "455      2019 2019-01-07 07:00:00+01:00  100047535  Pont du Garigliano NO-SE   \n",
       "456      2019 2019-01-07 08:00:00+01:00  100047535  Pont du Garigliano NO-SE   \n",
       "...       ...                       ...        ...                       ...   \n",
       "6521217  2024 2024-12-20 10:00:00+01:00  100047546  Face au 70 quai de Bercy   \n",
       "6521218  2024 2024-12-24 04:00:00+01:00  100047546  Face au 70 quai de Bercy   \n",
       "6521219  2024 2024-12-25 02:00:00+01:00  100047546  Face au 70 quai de Bercy   \n",
       "6521220  2024 2024-12-29 05:00:00+01:00  100047546  Face au 70 quai de Bercy   \n",
       "6521221  2024 2024-12-31 09:00:00+01:00  100047546  Face au 70 quai de Bercy   \n",
       "\n",
       "                  site_name           counter_id  \\\n",
       "452      pont du garigliano         100047535-SC   \n",
       "453      pont du garigliano         100047535-SC   \n",
       "454      pont du garigliano         100047535-SC   \n",
       "455      pont du garigliano         100047535-SC   \n",
       "456      pont du garigliano         100047535-SC   \n",
       "...                     ...                  ...   \n",
       "6521217       quai de bercy  100047546-103047546   \n",
       "6521218       quai de bercy  100047546-103047546   \n",
       "6521219       quai de bercy  100047546-103047546   \n",
       "6521220       quai de bercy  100047546-103047546   \n",
       "6521221       quai de bercy  100047546-103047546   \n",
       "\n",
       "                         counter_name  count               coords  \n",
       "452          pont du garigliano no-se      3   48.839927,2.267151  \n",
       "453          pont du garigliano no-se      1   48.839927,2.267151  \n",
       "454          pont du garigliano no-se     13   48.839927,2.267151  \n",
       "455          pont du garigliano no-se     55   48.839927,2.267151  \n",
       "456          pont du garigliano no-se    114   48.839927,2.267151  \n",
       "...                               ...    ...                  ...  \n",
       "6521217  face au 70 quai de bercy s-n     70  48.8295233, 2.38699  \n",
       "6521218  face au 70 quai de bercy s-n      0  48.8295233, 2.38699  \n",
       "6521219  face au 70 quai de bercy s-n      0  48.8295233, 2.38699  \n",
       "6521220  face au 70 quai de bercy s-n      4  48.8295233, 2.38699  \n",
       "6521221  face au 70 quai de bercy s-n     56  48.8295233, 2.38699  \n",
       "\n",
       "[737758 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in function\n",
    "%run ../scripts/normalize_datetime_hourly.py\n",
    "\n",
    "# raw file names\n",
    "raw_files_list = [ '2019_comptage-velo-donnees-compteurs.csv',\n",
    "                   '2020_comptage-velo-donnees-compteurs.csv',\n",
    "                   '2021_comptage-velo-donnees-compteurs.csv',\n",
    "                   '2022_comptage-velo-donnees-compteurs.csv',\n",
    "                   '2023_comptage-velo-donnees-compteurs.csv',\n",
    "                   '2024_comptage-velo-donnees-compteurs.csv']\n",
    "\n",
    "# columns of interest\n",
    "cols = ['Date et heure de comptage', \n",
    "        'Nom du site de comptage', \n",
    "        'Nom du compteur',\n",
    "        'Identifiant du site de comptage', \n",
    "        'Identifiant du compteur',\n",
    "        'Comptage horaire', \n",
    "        'Coordonnées géographiques']\n",
    "\n",
    "# read in raw data\n",
    "dfs = []\n",
    "for file in raw_files_list:\n",
    "    df = pd.read_csv(\n",
    "        RAW_DIR / file,\n",
    "        sep=\";\",\n",
    "        engine= \"pyarrow\", # ----- Use \"python\" engine while troubleshooting \n",
    "        usecols=cols,\n",
    "        #nrows = 100, # -----Uncomment while trouble shooting to speed up read time; does not work with \"pyarrow\" \n",
    "        dtype={\n",
    "            'Nom du site de comptage': 'string', \n",
    "            'Nom du compteur': 'string', \n",
    "            'Identifiant du site de comptage': 'string',\n",
    "            'Identifiant du compteur': 'string',\n",
    "            'Comptage horaire': 'Int64', \n",
    "            'Coordonnées géographiques' : 'object'\n",
    "        }\n",
    "    )\n",
    "    # handle unexpected .0 suffixes that crop up in 2024 file, probably a pyarrow parse issue\n",
    "    sid = (df[\"Identifiant du site de comptage\"]\n",
    "          .astype(\"string\")\n",
    "          .str.replace(\"\\u00a0\", \" \", regex=False)  # NBSP safety\n",
    "          .str.strip()\n",
    "    )\n",
    "    df[\"Identifiant du site de comptage\"] = (pd.to_numeric(sid, errors=\"coerce\")\n",
    "                                            .astype(\"Int64\")     \n",
    "                                            .astype(\"string\")    \n",
    "    )\n",
    "    df[\"year\"] = file[:4]\n",
    "    df = normalize_datetime_hourly(\n",
    "                                   df,\n",
    "                                   \"Date et heure de comptage\",\n",
    "                                   ambiguous=\"NaT\",\n",
    "                                   resolve_ambiguous=\"second\")\n",
    "    dfs.append(df)\n",
    "\n",
    "main_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# filter to sites of interest\n",
    "sites_of_interest = ['100047535', '100056226', '100047551', '100047542', '100047547', '100047546']\n",
    "main_df = main_df[ main_df['Identifiant du site de comptage'].isin(sites_of_interest)]\n",
    "\n",
    "# rename variables\n",
    "main_df.rename(columns={'Identifiant du compteur' : 'counter_id',\n",
    "                        'Nom du compteur' : 'counter_name',\n",
    "                        'Identifiant du site de comptage' : 'site_id',\n",
    "                        'Nom du site de comptage' : 'site_name_raw',\n",
    "                        'Comptage horaire' : 'count', \n",
    "                        'Date et heure de comptage': 'date_time_raw',\n",
    "                        'Coordonnées géographiques': 'coords',\n",
    "                        'Date et heure de comptage_dt' : 'date_time_dt'}, \n",
    "              inplace = True)\n",
    "\n",
    "# select and reorder columns\n",
    "main_df = main_df[ ['year', 'date_time_dt', 'site_id', 'site_name_raw',  'counter_id', 'counter_name',  'count', 'coords']]\n",
    "\n",
    "# convert names to lowercase (to normalize capitalization aross years)\n",
    "main_df['site_name'] = main_df['site_name_raw'].str.lower()\n",
    "main_df['counter_name'] = main_df['counter_name'].str.lower()\n",
    "\n",
    "# simplify site_name to describe loaciton in a general way\n",
    "main_df['site_name'] = (\n",
    "    main_df['site_name']\n",
    "    .str.replace(\"no-se|se-no\", \"\", regex = True)\n",
    "    .str.replace(\"face au 8 \",\"\", regex = True)\n",
    "    .str.replace(\"face au 48 \",\"\", regex = True)\n",
    "    .str.replace(\"face au 70 \",\"\", regex = True)\n",
    "    .str.replace(\"^6 \",\"\", regex = True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# select and reorder columns\n",
    "main_df = main_df[ ['year', 'date_time_dt', 'site_id', 'site_name_raw', 'site_name',  'counter_id', 'counter_name',  'count', 'coords']]\n",
    "\n",
    "# display\n",
    "print(main_df.dtypes)\n",
    "display(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483f4fcf-470a-4e27-ab1b-d35c091ff6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save the processed dataset for reuse\n",
    "# This step is disabled by default to avoid unnecessary file writes\n",
    "# Uncomment to write the data to disk\n",
    "main_df.to_parquet(DATA_DIR / \"extracted/extracted_hourly_bike_count_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
